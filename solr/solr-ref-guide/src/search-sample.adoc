= Searching, Sampling and Aggregation
// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

Data is the indispensable factor in statistical analysis. This section
provides an overview of the key functions for retrieving data for
visualization and statistical analysis: searching, sampling
and aggregation.

== Searching

=== Exploring

The *search* function can be used to search a Solr Cloud collection and return a
result set.

Below is an example of the most basic *search* function called from the Zeppelin-Solr interpreter.
Zeppelin-Solr sends the *seach(testapp)* call to the /stream handler and displays the results
in *table* format.


In the example the search function passed only the name of the collection being search. This returns
a result set of 10 records showing all fields in and unspecified order. This simple function is useful
for exploring the fields in the data and understanding how to start refining the search criteria.

image::images/math-expressions/search1.png[]

=== Searching and Sorting

Once the format of the records is known, parameters can be added to the *search* function to begin analyzing
the data.

In the example below a search query, field list, rows and sort have been added to the search
function. Now the search is limited to records within a specific time range and returns
a max result set of 750 records sorted by tdate_dt ascending. We have also limited the result set to three specific
fields.

image::images/math-expressions/search-sort.png[]


Once we have a the data loaded into the table we can switch to a scatter plot and plot the filesize_d column
on the *x axis* and the response_d column on the *y axis*.

image::images/math-expressions/search-sort-plot.png[]

This allows us to quickly visualize the relationship between two variables
selected from the a a specific slice of the index.

=== Scoring

The `search` function will score and rank documents when a query is performed on
a text field. The example below shows an example of this scoring and ranking of results.

image::images/math-expressions/scoring.png[]


== Sampling

The `random` function returns a random sample from a distributed search result set.
This allows for fast visualizations, statistical analysis and modeling of
samples that can be applied to the larger result set.

For the visualization examples below smaller random samples are used. But
Solr's random sampling provides sub-second
response times on sample sizes of over 200,000, which can be used to build
reliable statistical models that describe large data sets (billions of
documents) with sub-second performance.

The examples below demonstrate univariate and bivariate scatter
plots of random samples. Statistical modeling with random samples
is covered in the Statistics, Probability, Linear Regression, Curve Fitting
and Machine Learning sections of the user guide.

=== Univariate Scatter Plots

In the example below the `random` function is used to draw 500 random samples
from the *logs* collection. The query matches all log records and
the *filesize_d* field is returned with each sample.

The visualization below shows the *filesize_d* field plotted on both the x and y
axis which produces a diagnal line with a slop of 1. By studying the scatter plot
we can learn a number of things about the distribution of the *filesize_d*
variable:

* The sample set ranges from 34,070 to 46,456.
* The highest density appears to be at about 40,000.
* The sample seems to have a balanced number of observations above and below
40,000. Based on this the *mean* and *mode* would appear to be around 40,000.
* The number of observations tapers off to a small number of outliers on
the and low end of the sample.

This sample can be rerun multiple times to see if the samples
produce similar plots.

image::images/math-expressions/univariate.png[]

=== Bivariate Scatter Plots

In the next example two fields are returned with each sample: *filesize_d* and *response_d*.
By plotting filesize_d on the x axis and *response_d* on the y axis we can begin to study
the relationship between the two variables.

By studying the scatter plot we can learn the following:

* As filesize_d rises response_d tends to rise.
* This relationship appears to be linear, as a straight line put through the data could
be used to model the relationship.
* The points would cluster most densely
* The variance of the data at each *filesize_d* point seems fairly consistent. This means
a predictive model would have consistent error across the range of predictor values.

image::images/math-expressions/bivariate.png[]


== Aggregations

=== facet

=== facet2D

=== timeseries

=== significantTerms